{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Damage Detection using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G3_H7X0hZWW3",
    "outputId": "95c87c83-5994-46d4-da25-1dcdc619fe80"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import warnings\n",
    "import keras,os\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Flatten,Dense,Input,Conv2D,MaxPooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D, MaxPool2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input, decode_predictions\n",
    "from keras.engine.topology import get_source_inputs\n",
    "\n",
    "import matplotlib.pyplot as plt  # doctest: +SKIP\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to VGG16 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThlVgLlXddEJ"
   },
   "outputs": [],
   "source": [
    "model_path = \"vgg16_weights_tf_dim_ordering_tf_kernels.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture and Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tz3-pYGdxPF"
   },
   "outputs": [],
   "source": [
    "def VGG16(include_top=False, weights='imagenet',input_tensor=None, input_shape=None,pooling=None,classes=1000):\n",
    "    \"\"\"\n",
    "    VGG16 network. Further truncating the last 4 layers\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),dim_ordering=\"tf\",trainable=False))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),dim_ordering=\"tf\",trainable=False))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),dim_ordering=\"tf\",trainable=False))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),dim_ordering=\"tf\",trainable=False))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",dim_ordering=\"tf\",trainable=False))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),dim_ordering=\"tf\",trainable=False))\n",
    "    \n",
    "\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4096, activation='relu', name='fc1'))\n",
    "    model.add(Dense(4096, activation='relu', name='fc2'))\n",
    "    model.add(Dense(classes, activation='softmax', name='predictions'))\n",
    "    #weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',path,cache_subdir='models')\n",
    "    model.load_weights(model_path)\n",
    "    model.pop()\n",
    "    model.pop()\n",
    "    model.pop()\n",
    "    model.pop()\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    #model.add(Dense(25, activation='relu', name='fc1'))\n",
    "    #model.add(Dense(17, activation='relu', name='fc2'))\n",
    "    #model.add(Dense(15, activation='relu', name='fc3'))\n",
    "    #model.add(Dense(2, activation='softmax', name='predictions'))   \n",
    "    #model.summary()\n",
    "    print('Model ready...')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reUurb6jfXNH"
   },
   "outputs": [],
   "source": [
    "def feature_extraction(directory0):\n",
    "    \"\"\"\n",
    "    Calculate the forward pass output of VGG16 model. \n",
    "    This output if fed to dense network for bianry classification.\n",
    "    \"\"\"\n",
    "    X = np.arange(25088,dtype=int)\n",
    "    Y = np.array(0,dtype=int)\n",
    "    cnt = 0\n",
    "    for filename in os.listdir(directory0):\n",
    "#         cnt += 1\n",
    "#         if(cnt%100==0):\n",
    "#            print(cnt)\n",
    "        img = image.load_img(directory0+filename, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        #print('Input image shape:', x.shape)\n",
    "        preds = model.predict(x)\n",
    "        #print(preds.shape)\n",
    "        X = np.vstack((X,preds))\n",
    "        if 'damage' in directory0:\n",
    "            Y = np.vstack((Y,0))\n",
    "        else:\n",
    "            Y = np.vstack((Y,1))\n",
    "    X = X[1:]\n",
    "    Y = Y[1:]\n",
    "    print(X.shape,Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "g948YEoWfa2b",
    "outputId": "6f62277f-8dcb-4a67-9b3b-32df37ff8549",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(input_shape=(224, 224,..., filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  \n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  import sys\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), trainable=False, data_format=\"channels_last\")`\n",
      "  \n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), trainable=False, data_format=\"channels_last\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  \n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "  app.launch_new_instance()\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", trainable=False, data_format=\"channels_last\")`\n",
      "/home/sagar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), trainable=False, data_format=\"channels_last\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagar\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory0 = 'data1a/training/00-damage/'\n",
    "directory1 = 'data1a/training/01-whole/'\n",
    "directory2 = 'data1a/validation/00-damage/'\n",
    "directory3 = 'data1a/validation/01-whole/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction and Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "tmsiKSBRfc-p",
    "outputId": "1ae9def2-2fd4-4cc1-c8c2-48621880f65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920, 25088) (920, 1)\n",
      "(230, 25088) (230, 1)\n",
      "(230, 25088) (230, 1)\n",
      "(839, 25088) (839, 1)\n",
      "(1759, 25088) (460, 25088) (1759, 1) (460, 1)\n"
     ]
    }
   ],
   "source": [
    "X1, Y1 = feature_extraction(directory1)\n",
    "X2, Y2 = feature_extraction(directory2)\n",
    "X3, Y3 = feature_extraction(directory3)\n",
    "X0, Y0 = feature_extraction(directory0)\n",
    "\n",
    "X_train = np.vstack((X0,X1))\n",
    "Y_train = np.vstack((Y0,Y1)) \n",
    "X_test = np.vstack((X2,X3))\n",
    "Y_test = np.vstack((Y2,Y3))\n",
    "\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "sw_GCRUjsIwT",
    "outputId": "bf470809-5967-440e-8dc5-37a5350804d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 80)                2007120   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,010,401\n",
      "Trainable params: 2,010,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1583 samples, validate on 176 samples\n",
      "Epoch 1/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 1.6316 - accuracy: 0.8598 - val_loss: 2.1146 - val_accuracy: 0.7898\n",
      "Epoch 2/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 0.2713 - accuracy: 0.9621 - val_loss: 1.1125 - val_accuracy: 0.8807\n",
      "Epoch 3/10\n",
      "1583/1583 [==============================] - 2s 995us/step - loss: 0.0649 - accuracy: 0.9874 - val_loss: 1.0293 - val_accuracy: 0.8920\n",
      "Epoch 4/10\n",
      "1583/1583 [==============================] - 2s 998us/step - loss: 0.0753 - accuracy: 0.9867 - val_loss: 1.9563 - val_accuracy: 0.8807\n",
      "Epoch 5/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 1.8997 - val_accuracy: 0.8864\n",
      "Epoch 6/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 2.2708 - val_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "1583/1583 [==============================] - 2s 997us/step - loss: 2.8364e-04 - accuracy: 1.0000 - val_loss: 2.1462 - val_accuracy: 0.8693\n",
      "Epoch 8/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 5.7262e-05 - accuracy: 1.0000 - val_loss: 1.9726 - val_accuracy: 0.8807\n",
      "Epoch 9/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 1.6670e-05 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "1583/1583 [==============================] - 2s 1ms/step - loss: 9.6468e-06 - accuracy: 1.0000 - val_loss: 2.0448 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(80,input_dim = 25088, activation='relu', name='fc1'))\n",
    "model.add(Dense(40, activation='relu', name='fc2'))\n",
    "model.add(Dense(1, activation='sigmoid', name='predictions'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction over test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "sw_GCRUjsIwT",
    "outputId": "bf470809-5967-440e-8dc5-37a5350804d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460 430\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = model.predict(X_test)\n",
    "\n",
    "c=0\n",
    "cnt=0\n",
    "for i in range(len(y_test_nn)):\n",
    "    if(y_test_nn[i]>0.5):\n",
    "        y_test_nn[i]=int(1)\n",
    "    else:\n",
    "        y_test_nn[i]=int(0)\n",
    "for i in range(len(Y_test)):\n",
    "        c+=1\n",
    "        if(y_test_nn[i]==Y_test[i]):\n",
    "                cnt+=1\n",
    "print(c,cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "sw_GCRUjsIwT",
    "outputId": "bf470809-5967-440e-8dc5-37a5350804d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 219 11 19\n",
      "Accuracy of the model is 93.47826086956522\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "True_Positive = 0\n",
    "True_Negative = 0\n",
    "False_Positive = 0\n",
    "False_Negative = 0\n",
    "for i in range(len(y_test_nn)):\n",
    "  if(y_test_nn[i]==1 and Y_test[i]==1):\n",
    "    True_Positive += 1\n",
    "  if(y_test_nn[i]==0 and Y_test[i]==0):\n",
    "    True_Negative += 1\n",
    "  if(y_test_nn[i]==1 and Y_test[i]==0):\n",
    "    False_Positive += 1\n",
    "  if(y_test_nn[i]==0 and Y_test[i]==1):\n",
    "    False_Negative += 1\n",
    "\n",
    "print(True_Positive,True_Negative,False_Positive,False_Negative)\n",
    "\n",
    "Accuracy = (True_Positive + True_Negative) / (True_Positive + True_Negative + False_Positive + False_Negative) *100\n",
    "print(f'Accuracy of the model is {Accuracy}')\n",
    "\n",
    "C = confusion_matrix(y_test_nn, Y_test)  # doctest: +SKIP\n",
    "#print(C) # doctest: +SKIP\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cmap = ListedColormap(['r', 'g'])\n",
    "cax = ax.matshow(C,cmap = cmap)\n",
    "for (i, j), z in np.ndenumerate(C):\n",
    "    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
    "labels = ['Damaged', 'Cleaned']\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "feature.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
